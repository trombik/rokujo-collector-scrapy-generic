# Introduction

A collection of [Scrapy](https://docs.scrapy.org/) spiders designed to crawl web pages, scrape text content, and generate structured JSONL entries.

These JSONL entries serve as a foundation for further processing, such as creating collocation databases and assisting in the development of tools for translators.

Use cases:

* Create a collocation database from web articles.
* Create a database of source and target versions of web articles.
* Create a database of commonly used technical terms by experts.

In addition, some spiders collect files, linked from pages, such as PDF.
